# Adversarial Attack Study Plan

1. -[ ] Core Concepts (1-2 Weeks)
     - Adversarial Examples
     - Adversarial Perturbations
     - Robustness
     - Targeted Attacks
     - Untargeted Attacks
     - White-box Attacks
     - Black-box Attacks
     - Physical Attacks
2. -[ ] Classical Adversarial Attack Methods (2-3 Weeks)
     - FGSM (Fast Gradient Sign Method)
     - PGD (Projected Gradient Descent)
     - JSMA (Jacobian-based Saliency Map Attack)
     - Transfer-based Attacks
     - Surrogate Model Attacks
     - Query-based Attacks (e.g., ZOO, Boundary Attack)
     - Adversarial Patch
     - Lighting/Noise Perturbations (e.g., AdvCam)
3. -[ ] Practice (2-3 Weeks)
     - Implement FGSM/PGD using PyTorch or TensorFlow.
     - Utilize libraries such as Foolbox and ART (Adversarial Robustness Toolbox).
4. -[ ] Adversarial Defense Techniques (2-3 Weeks)
     - Robust Training Methods
     - Input Preprocessing
     - Model Architecture Improvements
     - Evaluation Metrics

## Study Resources

### Video
* https://www.youtube.com/watch?v=C8jJ4H6BL1c
* https://www.youtube.com/watch?v=pR2et-guixM
* https://www.youtube.com/watch?v=7P5zYUX5R9s

### Blog & Slide
* https://www.dremio.com/wiki/adversarial-attacks-in-ai/
* https://engineering.purdue.edu/ChanGroup/ECE595/files/chapter3.pdf

### ToolBox

* https://github.com/BorealisAI/advertorch
* https://github.com/bethgelab/foolbox
* https://github.com/tensorflow/cleverhans
* https://github.com/ppwwyyxx/Adversarial-Face-Attack
* https://github.com/IBM/adversarial-robustness-toolbox
* https://github.com/Trusted-AI/adversarial-robustness-toolbox
* https://github.com/Harry24k/adversarial-attacks-pytorch

### Awesome Repos

* https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval
* http://github.com/wangjksjtu/awesome-AML
* https://github.com/Yanxing-Shi/Awesome-CV-Adversarial-Attack-List
