# Adversarial Attack Study Plan

1. -[ ] Core Concepts (1-2 Weeks)
     - Adversarial Examples
     - Adversarial Perturbations
     - Robustness
     - Targeted Attacks
     - Untargeted Attacks
     - White-box Attacks
     - Black-box Attacks
     - Physical Attacks
2. -[ ] Classical Adversarial Attack Methods (2-3 Weeks)
     - FGSM (Fast Gradient Sign Method)
     - PGD (Projected Gradient Descent)
     - JSMA (Jacobian-based Saliency Map Attack)
     - Transfer-based Attacks
     - Surrogate Model Attacks
     - Query-based Attacks (e.g., ZOO, Boundary Attack)
     - Adversarial Patch
     - Lighting/Noise Perturbations (e.g., AdvCam)
3. -[ ] Practice (2-3 Weeks)
     - Implement FGSM/PGD using PyTorch or TensorFlow.
     - Utilize libraries such as Foolbox and ART (Adversarial Robustness Toolbox).
4. -[ ] Adversarial Defense Techniques (2-3 Weeks)
     - Robust Training Methods
     - Input Preprocessing
     - Model Architecture Improvements
     - Evaluation Metrics

